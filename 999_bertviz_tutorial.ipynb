{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":" bertviz_tutorial.ipynb","provenance":[{"file_id":"1MV7u8hdMgpwUd9nIlONQp-EBo8Fsj7CJ","timestamp":1644019621685}],"collapsed_sections":[],"authorship_tag":"ABX9TyPK6Aqu/U/TTXkf1pDtmglM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# BertViz Interactive Tutorial\n","### ‚ö†Ô∏è **Note: You do not need to execute any cells.** ‚ö†Ô∏è\n","### **Scroll down for pre-loaded visualizations** üëáüëáüëáüëáüëáüëá"],"metadata":{"id":"-GlgO5WBOYeF"}},{"cell_type":"code","source":["!pip install bertviz"],"metadata":{"id":"aR07__FyOf8a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load model and retrieve attention weights\n","\n","from bertviz import head_view, model_view\n","from transformers import BertTokenizer, BertModel\n","\n","model_version = 'bert-base-uncased'\n","model = BertModel.from_pretrained(model_version, output_attentions=True)\n","tokenizer = BertTokenizer.from_pretrained(model_version)\n","sentence_a = \"The cat sat on the mat\"\n","sentence_b = \"The cat lay on the rug\"\n","inputs = tokenizer.encode_plus(sentence_a, sentence_b, return_tensors='pt')\n","input_ids = inputs['input_ids']\n","token_type_ids = inputs['token_type_ids']\n","attention = model(input_ids, token_type_ids=token_type_ids)[-1]\n","sentence_b_start = token_type_ids[0].tolist().index(1)\n","input_id_list = input_ids[0].tolist() # Batch index 0\n","tokens = tokenizer.convert_ids_to_tokens(input_id_list) "],"metadata":{"id":"TG-dQt3NOlub"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Head View\n","<b>The head view visualizes attention in one or more heads from a single Transformer layer.</b> Each line shows the attention from one token (left) to another (right). Line weight reflects the attention value (ranges from 0 to 1), while line color identifies the attention head. When multiple heads are selected (indicated by the colored tiles at the top), the corresponding  visualizations are overlaid onto one another.  For a more detailed explanation of attention in Transformer models, please refer to the [blog](https://towardsdatascience.com/deconstructing-bert-part-2-visualizing-the-inner-workings-of-attention-60a16d86b5c1).\n","\n","## Usage\n","üëâ **Hover** over any **token** on the left/right side of the visualization to filter attention from/to that token. <br/>\n","üëâ **Double-click** on any of the **colored tiles** at the top to filter to the corresponding attention head.<br/>\n","üëâ **Single-click** on any of the **colored tiles** to toggle selection of the corresponding attention head. <br/>\n","üëâ **Click** on the **Layer** drop-down to change the model layer (zero-indexed).\n"],"metadata":{"id":"YLAhBxDSScmV"}},{"cell_type":"code","source":["head_view(attention, tokens, sentence_b_start)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":408,"output_embedded_package_id":"1A329X6PsiTfOaIWoyhNpEk3MEZkF95Yg"},"id":"twSVFOM9SopW","executionInfo":{"status":"ok","timestamp":1644069105464,"user_tz":480,"elapsed":4400,"user":{"displayName":"J V","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07948735691163359224"}},"outputId":"e206bbf5-2ba8-4b17-827b-79239f97d33f"},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["# Model View\n","<b>The model view provides a birds-eye view of attention throughout the entire model</b>. Each cell shows the attention weights for a particular head, indexed by layer (row) and head (column).  The lines in each cell represent the attention from one token (left) to another (right), with line weight proportional to the attention value (ranges from 0 to 1).  For a more detailed explanation, please refer to the [blog](https://towardsdatascience.com/deconstructing-bert-part-2-visualizing-the-inner-workings-of-attention-60a16d86b5c1).\n","\n","## Usage\n","üëâ **Click** on any **cell** for a detailed view of attention for the associated attention head (or to unselect that cell). <br/>\n","üëâ Then **hover** over any **token** on the left side of detail view to filter the attention from that token."],"metadata":{"id":"o2L6axGyOt5K"}},{"cell_type":"code","source":["model_view(attention, tokens, sentence_b_start)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"19yI0WM1_eNgZf3sfA0Gic_8IaKNeBLy6"},"id":"T3H0qUZvPOP4","executionInfo":{"status":"ok","timestamp":1644069105464,"user_tz":480,"elapsed":35,"user":{"displayName":"J V","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07948735691163359224"}},"outputId":"8ab4eac1-b8a7-4710-e969-d67b0e168b33"},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["# Neuron View\n","<b>The neuron view visualizes the intermediate representations (e.g. query and key vectors) that are used to compute attention.</b> In the collapsed view (initial state), the lines show the attention from each token (left) to every other token (right). In the expanded view, the tool traces the chain of computations that produce these attention weights. For a detailed explanation of the attention mechanism, please refer to the [blog](https://towardsdatascience.com/deconstructing-bert-part-2-visualizing-the-inner-workings-of-attention-60a16d86b5c1).\n","\n","## Usage\n","üëâ **Hover** over any of the tokens on the left side of the visualization to filter attention from that token.<br/>\n","üëâ Then **click** on the **plus** icon that is revealed when hovering. This exposes the query vectors, key vectors, and other intermediate representations used to compute the attention weights. Each color band represents a single neuron value, where color intensity indicates the magnitude and hue the sign (blue=positive, orange=negative).<br/>\n","üëâ Once in the expanded view, **hover** over any other **token** on the left to see the associated attention computations.<br/>\n","üëâ **Click** on the **Layer** or **Head** drop-downs to change the model layer or head (zero-indexed).\n"],"metadata":{"id":"EYUPfoEWPxt_"}},{"cell_type":"code","source":["from bertviz.transformers_neuron_view import BertModel, BertTokenizer\n","from bertviz.neuron_view import show\n","\n","model_type = 'bert'\n","model_version = 'bert-base-uncased'\n","model = BertModel.from_pretrained(model_version, output_attentions=True)\n","tokenizer = BertTokenizer.from_pretrained(model_version, do_lower_case=True)\n","show(model, model_type, tokenizer, sentence_a, sentence_b, layer=4, head=3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":546,"output_embedded_package_id":"1jVZmE4hFBLFLP5rJatVmuN5DQAIVvTix"},"id":"-QnRteSLP0Hm","executionInfo":{"status":"ok","timestamp":1644069170660,"user_tz":480,"elapsed":15671,"user":{"displayName":"J V","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07948735691163359224"}},"outputId":"ee2f57d9-ba11-4f66-b19e-e6e9ddaae18d"},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["# Next steps\n","\n","Visit the [github repository](https://github.com/jessevig/bertviz) for full documentation and additional use cases. Check out the [blog](https://towardsdatascience.com/deconstructing-bert-part-2-visualizing-the-inner-workings-of-attention-60a16d86b5c1) for a deep dive on BertViz and the attention mechanism. "],"metadata":{"id":"9thTgP1AKYii"}}]}